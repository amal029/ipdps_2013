\section{Implementation}
\label{sec:imple}

We follow a bottom up approach when clustering onto the virtual nodes
from the resource graph and top down approach when
In order to implement our heuristic we use METIS \cite{} graph
partitioning tool.

bullshit about metis.

The resource graph is generated by assuming the capabilities lie in a
fixed range. Using this we define a range from which we assign the
respective PE's capabilities. In generating them synthetically we avoid
being biased by a single architecture and we can evaluate our system
for different characteristics. The interconnect is considered to be two
dimensional mesh with varying bandwidths. Thus, making both the
computaions and communication be truly hetrogeneous.

Once we have the resource graph, we perform the clustering as describe
in section \ref{sec:gener-reso-graph}. We use metis to do the
clustering of the nodes based on communication volume min cut and load
balance constraints. The entire process is described below:

\begin{itemize}

\item The generated resource is graph is represented in the Metis
graph format. We represent the PEs capabilities as constraints of the
nodes and the link's bandiwdths as communication volume of the edges.

\item We then construct our clustered structre by halving the nodes at
each level. Metis partitions the graph by load balancing the
constraints and min cut communication. So the number of partitions
that it might provide might be less than that being requested.

\item When constructing the new virtual node, the constraints of the
previous are aggregated and the communication is calculated by summing
the minimum bandwidths of links connecting the nodes present in the
different partitions.

\item We repeat the clustering for each level, until we reach a stage
in which all the PEs form a single partition.

\end{itemize}

In partitioning the task graph, we need to balance the constraints on
to the available partitions. Metis offers the ability to load balance
multiple constraints on to different partitions based on the metric 'tp
weight'. We calculate the ratios between the capabilities of different
partitions and represent as this metric in order to load balance on to
the available partitions. The steps through which task graph follows
are,

\begin{itemize}

\item We start at the top most level in the resource graph and request
for the number of partitions equal to that of the child nodes at the
next level.

\item The capabilities of the resource graph are represented as ratios
for each of the constraint as the 'tp weight' metric when partitioning
the task graph using Metis.

\item As we go down on to each level we partition the task graph into
smaller fine grained parts until we reach the lowest level.

\item Finally, the entire task graph is partitioned into sub graphs
where each of them are mapped onto a specific PE in the resource graph.

\end{itemize}

\subsection{Load Balancing Multiple Constraints}

Metis load balances constraints by minimizing the imbalance with that
of a ideal value. It tries to acheive this by modifying the
partitioning such that each consrtaint lies within certain imbalance
from the ideal value. Since reaching a 'optimal' solution is difficult
here, it matches each of the constraint in order until it finds a
solution where all the constraints are matched within a certain
tolerance level. Unfortunately, this causes the contraint to be
matched with more and more imbalance as we move further.

In order to handle this, we chose an addition to our heuristic that
checks whether we achieve the least imbalance in compute power in our
partitions. This is done by clustering the nodes at each level based
on all the possible permutations of the resource graph. After each
clustering for a given permutation the imbalance in compute power is
calculated as,

\begin{equation}
\begin{array}{c}
desired_compute_power = total_compute_power / no_of_nodes;\\

for each partition, for 1->n\\
cp_n = sum( ( compute power of node ( R * R .. Rn ) ) -
desired_compute_power )\\

chosen partition = min( cp_n  )\\
\end{array}
\end{equation}

We then pick the partition that was yielded with the minimum deviation
in the compute power.


