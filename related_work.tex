\section{Related work}
\label{sec:related-work}

A significant amount of existing research aims to extract parallelism
from programs~\cite{mgri98,mgor06,gsih93}. The
polyhedral optimization model~\cite{mgri98} concentrates on
automatically extracting data parallelism from loops operating on
arrays. The polyhedral optimization community has addressed
parallelization for CPUs and GPUs separately, but to our knowledge has
not explored the combination of the two.

Carpenter et. al~\cite{pcar09} provide a heuristic algorithm for
partitioning stream programs onto heterogeneous architectures.
However, the heterogeneity of processors is represented purely by
their clock speed. No distinction is made between processors with
differing amounts of vector parallelism.

The StreamIt~\cite{Thies2009} community also address the problem of
scheduling and partitioning stream programs onto homogeneous parallel
hardware, such as the RAW~\cite{ewai97} architecture. StreamIt can
exploit data parallelism, by replicating stateless filters, but it
does not exploit vector parallelism.

Classical algorithms such as critical path
scheduling~\cite{Kohler1975} and list scheduling~\cite{atho74}
are used for scheduling task parallelism onto homogeneous
architectures. The list scheduling techniques targeting heterogeneous
architectures such as~\cite{htop02} do not exploit vector SIMD
parallelism. Declustering~\cite{gsih93}, is another technique for
partitioning tasks to parallel hardware, which again does not consider
vector parallelism.

Cluster based partitioning techniques~\cite{tbra01}
consider only independent tasks without communication. The proposed
heuristics for partitioning data-parallel applications onto
clusters~\cite{ssan05,skum02} do not consider vectorization potential
available on the compute clusters and only concentrate on partitioning
task parallel processes.

Heuristic optimization techniques such as genetic algorithms
(GA) and Simulated annealing~\cite{265940,shroff1996genetic} and local search
methods~\cite{622584} use a semi-random search of the space of possible
partitions filters on to execution resources. The effectiveness of these
techniques often depends on choosing good values for parameters to the
algorithm. Determining good values for these parameters is a difficult problem
that often requires trial and error.

Malik et al. 2012~\cite{Malik2012}, similar to our technique partitions stream
graphs onto heterogeneous architectures consisting of CPUs and GPUs based on a
mathematical integer linear programming formulation (ILP) to provide optimal
solutions but, does not scale well to large architectures or stream graphs.
Hence, ILP is more suitable for small
embedded systems, whereas our work is more suited for HPC systems. Sui et al.
2010~\cite{Sui:2010:PGP:1964536.1964553} focus on extracting amorphous
parallelism, which occur in irregular algorithms working on graph
data-structures similar to Metis~\cite{gkar95}. We on the other hand target
streaming applications, and extract data and task-parallelism, which are
commonly occurring forms of parallelism on SIMD and MIMD architectures. Thus,
our work is orthogonal to that of Sui et al. Same can be stated about Catalyurek
et al. 2001~\cite{Catalyurek:2001:HAC:582034.582062}.
