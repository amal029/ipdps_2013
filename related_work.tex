\section{Related work}
\label{sec:related-work}

A significant amount of research literature exists for extracting
parallelism from programs~\cite{mgri98,jdon06,mgor06,gsih93,pcar09}. The
polyhedral optimization model~\cite{mgri98} concentrates on extracting
parallelism from loops, which is a form of data-parallelism. The
polyhedral optimization community has concentrated on optimizing for
CPUs and GPUs separately, but to our knowledge has not explored the
combination of the two. Carpenter et. al~\cite{pcar09} have again
explored ideas for partitioning onto heterogeneous architectures, but at
a much smaller scale and again ignoring data-allocation costs and
depending upon the polyhedral model for vectorization. The
StreamIt~\cite{wthi02} community has also explored parallelization
techniques, but they have only targeted homogeneous RAW~\cite{ewai97}
architecture. There are the classical algorithms such as critical path
scheduling~\cite{Kohler1975} and list scheduling~\cite{atho74}, which
have been used for scheduling task parallel process onto homogeneous
architectures. The list scheduling techniques targeting heterogeneous
architectures such as~\cite{htop02} do not exploit SIMD parallelism onto
vector processors. Declustering~\cite{gsih93}, is another technique,
which misses the opportunity to mix SIMD and task-parallel optimizations
together.

Cluster based partitioning techniques~\cite{mmah99,adou04,tbra01} only
consider independent tasks without communication. The proposed
heuristics for partitioning data-parallel applications onto
clusters~\cite{ssan05,skum02} do not consider vectorization potential
available on the compute clusters and only concentrate on partitioning
task parallel processes.

Random search techniques when combined with a certain objective use random
choices to guide them through a search space to arrive at a solution. The
objective is mostly derived from information obtained from previous random
searches or prior information about the system. Genetic Algorithms~\cite{} are the
commonly used from this technique and generate reasonably good results but
this requires significantly more time than heusristic based
alogirthms~\cite{}. Moreover determining optimal parameters to fine tune these
random techniques to get good results is a challenge. Parameters that give
good results for a certain scenario may not be the same for a different one.
Several other techniques also exist that belong to the same category in
addition to GA such as simulated Annealing~\cite{} and local search
methods~\cite{} suffer from the same disadvantages.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "bare_conf"
%%% End:
