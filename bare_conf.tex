% -*- mode:latex; mode:flyspell -*-
\documentclass[10pt, conference, compsocconf]{IEEEtran}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \usepackage{color}
  \usepackage{epstopdf}
  %\usepackage[update]{eps2pdf}
  %\usepackage[pdf]{pstricks}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi


%\usepackage{bibspacing}
% \setlength{\bibspacing}{\baselineskip}

% *** MATH PACKAGES ***
%
\usepackage{multirow}
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
\usepackage[tight,footnotesize]{subfigure}
\usepackage{fancyvrb}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



\usepackage{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/

%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.

\usepackage{fmtcount}



% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
% \hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{xspace}
\usepackage{bm}
\newcommand{\numtplgynodes}{\ensuremath{|V_r|}\xspace}
\newcommand{\gpunum}{\ensuremath{N_G}\xspace}
\newcommand{\veclenset}{\ensuremath{\bm{G}}\xspace}
\newcommand{\mipsset}{\ensuremath{\bm{M}}\xspace}
\newcommand{\corenumset}{\ensuremath{\bm{C}}\xspace}
\newcommand{\expt}{\ensuremath{\bm{E}}\xspace}
\newcommand{\bw}{\ensuremath{\bm{B}}\xspace}
\newcommand{\ul}{\underline}
\newcommand{\noname}{The NoNamer\xspace}

%squeeze

\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\raggedbottom

\addtolength{\floatsep}{-8mm}
\addtolength{\textfloatsep}{-6mm}
\addtolength{\intextsep}{-2mm}
\addtolength{\dbltextfloatsep}{-6mm}
\addtolength{\dblfloatsep}{-1mm}
\addtolength{\abovecaptionskip}{-1mm}
\addtolength{\belowcaptionskip}{-1mm}

\addtolength{\abovedisplayskip}{-3mm}
\addtolength{\belowdisplayskip}{-3mm}
\addtolength{\arraycolsep}{-1mm}

\let\oldthebibliography=\thebibliography
\let\endoldthebibliography=\endthebibliography
\renewenvironment{thebibliography}[1]{%
  \begin{oldthebibliography}{#1}%
    \setlength{\parskip}{0.2ex}%
    \setlength{\itemsep}{0.2ex}%
}%
{%
  \end{oldthebibliography}%
}

%squeeze

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Hetrogeneous Multiconstraint Application Partitioner (HMAP)}
%- \\Exploiting parallelism in a hetrogeneous HPC environment}
% \title{A framework for design space exploration for HPC architectures}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

%~ \author{\IEEEauthorblockN{Servesh Muralidharan, Aravind Vasudevan, David Gregg}
%~ \IEEEauthorblockA{School of Computer Science and\\Statistics\\
%~ Trinity College Dublin\\
%~ Dublin 2, Ireland\\
%~ Email: muralis@tcd.ie}
%~ \and
%~ \IEEEauthorblockN{David Gregg}
%~ \IEEEauthorblockA{School of Computer Science and\\Statistics\\
%~ Trinity College Dublin\\
%~ Dublin 2, Ireland\\
%~ Email: David.Gregg@cs.tcd.ie}}
%~
%~ \author{\IEEEauthorblockN{Authors Name/s per 1st Affiliation (Author)}
%~ \IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
%~ line 2: name of organization, acronyms acceptable\\
%~ line 3: City, Country\\
%~ line 4: Email: name@xyz.com}
%~ \and
%~ \IEEEauthorblockN{Authors Name/s per 2nd Affiliation (Author)}
%~ \IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
%~ line 2: name of organization, acronyms acceptable\\
%~ line 3: City, Country\\
%~ line 4: Email: name@xyz.com}
%~ }

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
%
\author{\IEEEauthorblockN{Servesh Muralidharan\IEEEauthorrefmark{2},
Aravind Vasudevan\IEEEauthorrefmark{2},
Avinash Malik\IEEEauthorrefmark{4}
%Shoukat Ali\IEEEauthorrefmark{4}
and
David Gregg\IEEEauthorrefmark{2}}
\IEEEauthorblockA{\IEEEauthorrefmark{2}School of Computer Science and Statistics,
Trinity College Dublin, Dublin 2, Ireland\\
Email: muralis@scss.tcd.ie, vasudeva@scss.tcd.ie, David.Gregg.cs.tcd.ie }
\IEEEauthorblockA{\IEEEauthorrefmark{4}IBM Research - Ireland\\
Email: avinmali@ie.ibm.com}
}

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}

% make the title area
\maketitle


\begin{abstract}
  In this article we propose a novel framework -- \textit{Hetrogeneous
  Multiconstraint Application Partitioner} (HMAP) for exploiting parallelism on
  heterogeneous \textit{High Performance Computing} (HPC) architectures. Given
  an hetrogeneous HPC cluster with varying compute units, communication
  constraints and topology, HMAP framework can be utilized for partitioning
  applications exhibiting task and data parallelism resulting in increased
  performance. The challenge lies in the fact that heterogeneous compute
  clusters consist of processing elements exhibiting different compute speeds,
  vector lengths, and communication bandwidths, which all need to be considered
  when partitioning the application and associated data. We tackle this problem
  using a staged graph partitioning approach. HMAP framework finishes within
  seconds even for architectures with 100's of processing elements, which makes
  our algorithm suitable for exploring parallelism potential.

  % In this paper we solve the problem of partitioning applications with a
  % mixture of both: filter-parallel and data-parallel parts onto
  % heterogeneous compute clusters. The challenge lies in the utilization
  % of vector and non-vector processing elements, while accounting for
  % varying communication latencies and bandwidths. We propose a graph
  % partitioning heuristic, which clusters a heterogeneous topology into a
  % homogeneous one and then partitions the applications onto the
  % resultant cluster in stages. Our experiments show that our approach is
  % results in X\% better application run-times, while being fast making
  % it suitable as a compilation time technique.

\end{abstract}

\begin{IEEEkeywords}
  Graph partitioning, vectorization, data parallelism, heterogeneous
  architectures, clusters.
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\input{introduction}

\begin{SaveVerbatim}[]{VerbEnv}
 //Task and data-parallel
 for (int i=0;i<999; ++i){
  for (int j=0;j<999; ++j){
   1: A[i][j] = (i*j+2.0+2.0/1000)
   2: B[i][j] = (i*j+3.0+3.0/1000)
  }
 }
 for (int k=0;k<1000;++k){
  for (int i=1; i<998; ++i)
   for (int j=1; j<998; ++j)
    3: B[i][j] = 0.2*(A[i][j]+A[i][j-1]
              +A[i][j+1]+A[i-1][j])

  //Data-parallel
  for (int i=1; i<999; ++i)
   for (int j=1; j<999; ++j)
    4: A[i][j] = B[i][j]
 }
\end{SaveVerbatim}

\addtocounter{footnote}{1}

\begin{figure*}[t!]
  \centering
  \subfigure[Example 2-dimensional Jacobi application]{
    \BUseVerbatim[fontshape=tr,fontsize=\small,fontfamily=courier]{VerbEnv}
    \label{fig:1a}
  }
  \subfigure[The filter graph for the Jacobi example
  $^{\decimal{footnote}}$]{
    \includegraphics[scale=0.44]{./figures/jacobi2d}
    \label{fig:1b}
    % \scalebox{0.37}{\input{./figures/jacobi2d-eps-converted-to.pdf}
  }
  \caption{Jacobi example and its filter-graph}
  \label{fig:1}
\end{figure*}


\section{Preliminaries}
\label{sec:preliminaries}

We now present a formal description of the problem along with the
notations used.

\subsection{Execution model}
\label{sec:execution-model}

In this paper we consider the streaming~\cite{jbuck94} model of
computation. Streaming is a popular model for programs such as image and
signal processing, financial applications, networking,
telecommunications, etc.

In the streaming model statements (also called filters/actors/tasks or
kernels) execute iteratively, processing the incoming tokens of
data. Consider the Jacobi example and its filter graph in
Figure~\ref{fig:1}. The Jacobi algorithm is used in fluid dynamics and
heat transfer problems. We consider every statement (marked $1$ to $4$)
in this example to be a filter that can be run in a software
pipelined~\cite{audu09} manner on a given architecture. An
\textit{example} execution trace of the Jacobi example is shown in
Table~\ref{tab:3} for some arbitrary value of computation and
communication latency of statements.

\begin{table}[h!]
  \centering
  \begin{tabular}{|c|c|c||c|c|c||c|}
    \hline
    P0 & $1_0$ & $2_0$ & $1_1$ & & $2_1$ & $1_2$\\
    \hline
    P1 & & $3_0$ & $4_0$ & $4_0$ & $3_1$ & $4_1$\\
    \hline
  \end{tabular}
  \caption{Example execution trace of the Jacobi kernel}
  \label{tab:3}
\end{table}

In a software pipelined model, the different iterations of the filters
are run in parallel, e.g., $1_0$ is the $1^{st}$ iteration of statement
$1$ in the Jacobi example, while $1_1$ is the second iteration and so on
and so forth. The latency of the application (termed makespan) is the
total time taken by the application for execution, which iterates continuously (shown within the double lined
columns in Table~\ref{tab:3}). In such a model, the resource allocation
(rather than dependencies) determines the application latency,
especially without back-edges in the filter graph (as is the case with
our model). In Table~\ref{tab:3}, the resource allocation on processing
element \texttt{P1} determines the application latency, because that is
the maximum of the two allocation latencies.

\subsection{Notations}

We refer to our application graph, as a \textit{Synchronous DataFlow }
(SDF) graph defined formally as a weighted directed graph: $G_t(V_t,
E_t)$, where $V_t$ is the set of all filters in the application graph
and $E_t$ represents the communication buffers between these
filters. The system resources are represented by a weighted undirected
graph $G_r(V_r, E_r)$ where $V_r$ represents a set of processing
elements (PEs) which can have different processing capabilities and
$E_r$ represent the communication links between these PEs with differing
latencies and bandwidths. % Each vertex in the filter graph, $t_i \in V_t$
% is referred to as a filter and each vertex in the resource graph, $r_i
% \in V_r$ is referred to as a processing element
% (PE). % We use $N_T$ to denote
% the total number of filters in the filter graph and $N_R$ to denote
% the total number of processing elements. By our definition of previous
% notations, it follows that $N_T = |V_t|$ and $N_R = |V_r|$.

\subsection{Problem Definition}

Given a graph $G_t(V_t, E_t)$, each vertex in the filter graph, $t_i \in
V_t$ has a set of associated requirements represented by $T^{i}_{j}$
where $j=0...n_t$ with $n_{t-1}$ being the number of requirements. These
requirements represent the computational requirements of the
filter. Namely, $T^i_0$ represents the scalar requirements, while
$T^i_1$ represents the vector requirements.

%~ Consider the filter graph in Figure~\ref{fig:1} for the running
%~ Jacobi example. The \texttt{boxed} statements give the number of
%~ instructions and the vector count requirements ($T^i_0\ \mathrm{and}\
%~ T^i_1$), i.e., $n_t=2$ for this example.

The communication edges are decorated with \mbox{$e^c \in E_t$}, which
denotes the data the filter requires for processing.
% ~ $(t_i,t_j) \in E_t$ ~ between data-stores (statements without the
% constraints ~ in Figure~\ref{fig:1}) and the execution statements ~
% represent the amount of data that needs to be transferred from the ~
% store and its utilization at the statement level, denoted by $e^c, ~
% \forall E_t \in (V_t \times V_t)$.  The filter graphs are generated
% directly from the program by our compiler. More information about the
% generation of the filter graphs is provided later in
% Section~\ref{sec:build-appl-graph}.

% From the perspective of the running example, constraint 0 of the first
% statement ($3$), represented by $T^{1}_{c0}$ denotes ----Avinash add
% some text here referring to the running jacobi example please----. Each
% edge $(t_i, t_j) \in E_t$ corresponds to the amount of data that has to
% be transferred from filter $t_i$ to filter $t_j$.

% Similarly we have a resource graph $G_r(V_r, E_r)$ where each vertex
% denotes a processing element (PE).  ~ It consists of a set of vertices
% $V_r = ~ \{r_1, r_2, ... , r_n\}$ and a set of edges $E_r$.

Each resource node $r_i \in V_r$ has a number of computational
capabilities, represented by $R^{i}_{j}$ where $j=0...n_{r-1}$.
%~ with $n_r$ being the number of constrains for the resource node.
%~ Please note that for some resource graph shown in Figure~\ref{fig:res}
%~ (level 0), which has $|V_r|$ nodes and 2 capabilities.
For each node, capability: $R^i_0$ represents the frequency of the PE or
how many scalar instructions the PE can perform in one second (the
\textit{Million Instructions Per Second} (MIPS) count). Capability :
$R^i_1$ denotes the maximum number of parallel vector operations it can
perform (the vector length). Each edge $e \in E_r$ has a weight which
represents the bandwidth between two PEs $r_i$ and $r_j$ which is
denoted by $E^c$.

% While generating the resource graph, we might have to contract edges(becaus we
% contract nodes). Contracting an edge $e=\{i,j\}$ means to replace vertices $i$ and
% $j$ by a new vertex $k$ such that $R^k_0 = R^i_0 + R^j_0$ and $R^k_1 = R^i_1 +
% R^j_1$. All edges of the form $\{i,x\}$ and $\{j,x\}$ for $x \in V_r$ are replaced
% by $\{k,x\}$. If both edges $\{i,x\}$ and $\{j,x\}$ exist, we form the new edge weight
% as defined by $E^{\{w,x\}} = E^{\{i,x\}} + E^{\{j,x\}}$ More information about the
% generation about the generation of the resource graphs is provided later in
% Section~\ref{sec:gener-reso-graph}.

The problem at hand is to effectively map the filter graph $G_t$ onto
given resource graph $G_r$. This problem is known to be
NP-Hard~\cite{vsar89}. % This immediately implicates that we have to look
% for heuristic solutions.

%~ For evaluating our mapping, we adapt a cost function used by numerous
%~ other papers~\cite{ssan05,ajai04,dajw12} for our setup.

Given some filter $t_i \in V_t$ mapped to some resource $r_j \in V_r$,
the latency for that node is computed by Equation~(\ref{eq:3}). In this
formulation for some filter $t_i$ being mapped onto some resource $r_j$,
we first calculate the number of vectorized instructions that can be
executed in parallel (by dividing the required vector length by the
vector capacity of $r_j$ represented by $R^j_1$). We then multiply this
by the number of iterations in the loop to get the total number of instructions to be performed by that
filter-graph node. Once we have this number we calculate latency of
execution of this filter-graph node $t_i$ on this resource $r_j$ by
dividing it with the MIPS value of the resource denoted by
$R^j_0$. Calculation of the communication latency requires dividing the
number of bits by the bandwidth of the shortest path.

Given the filter-graph and the resource-graph, let $\mathcal{M}$ be some
mapping of the application on the resource-graph. For a particular
allocation onto some resource node $r_s \in V_r$, we define its
computation and communication latency as in Equation~(\ref{eq:1}).

%\vspace{-0.7cm}

\begin{scriptsize}
\begin{equation}
  \label{eq:3}
  \begin{array}{c}
    ((T^i_1/R^j_1\times T^i_0)/R^j_0)
    + (e^c/E^{c'}) | c = (t_i,t_k), t_k \neq t_i, \\ \forall t_k \in V_t, c' =
    (r_j,r_l), r_l \neq r_j, \forall r_l \in V_r
  \end{array}
\end{equation}
\end{scriptsize}

\begin{figure}[h!]
\begin{scriptsize}
\begin{equation}
  \begin{array}{c}
    L^{\mathcal{M}}_s = Lcomp^{\mathcal{M}}_s +
    Lcomm^{\mathcal{M}}_s\\
    \\Lcomp^{\mathcal{M}}_s =
    \sum_{\forall t_i \in V_t} ((T^i_1/R^s_1\times T^i_0)/R^s_0)\\
    \\Lcomm^{\mathcal{M}}_s =
    \sum_{\forall t_i \in V_t} e^c / E^{c'}\\
    \\s.t., d = (t_i,t_k), t_k \neq t_i, \forall t_k
    \in V_t \wedge\  c' = (r_s,r_l), r_l \neq r_s, \forall r_l \in V_r \\
    \wedge\ \mathrm{d\ is\ routed\ on\ c'}
  \end{array}
  \label{eq:1}
\end{equation}
\end{scriptsize}
\end{figure}

\vspace{-3mm}

Finally, the complete application latency can then be defined as:
\begin{scriptsize}
\begin{equation}
  \label{eq:2}
  L^{\mathcal{M}} = max ({L^{\mathcal{M}}_s}), \forall r_s \in V_r
\end{equation}
\end{scriptsize}

\vspace{-6mm}

The objective of our framework is to find a mapping $\mathcal{M}$
that minimizes the total application latency as described in
Equation~(\ref{eq:2}).

% \subsection{Key Contributions}
% Our key contributions in the article are as follows:
% \begin{itemize}
% \item A novel way for compiler writers and software programmers to gauge
%   the potential performance of their programs on any given architecture.
% \item A framework that allows topology designers to efficaciously
%   explore the design space to determine the type of underlying
%   architecture that would suit a given application.
% \item A new heuristic based framework that exploits filter and data
%   parallelism exhibited by applications for mapping them onto
%   heterogeneous HPC architectures.
% \item Along with mapping application-filters onto resource nodes, the
%   framework also allocates data-stores being utilized by the different
%   application-filters.
% \item A rigorous experimental setup to analyse the effectiveness of our
%   framework.
% \end{itemize}

\footnotetext[\value{footnote}]{Ellipses represent data stores. Rectangles
  represent filter nodes. Rounded rectangle represents data parallel
  nodes. The dots represent other data parallel nodes not shown in the
  figure. Dashed arrows represent communication between data stores and
  execution statements. Solid arrows represent dependence edges.}

\section{HMAP framework}
\label{sec:our-framework}

A common approach to solving the homogeneous case is to
\textit{partition} the graph across the processing
elements~\cite{aale01,kpur99,enys98}.  However, we have found that such
heuristic partitioning approaches do not work well for heterogeneous
architectures. Instead we propose a novel approach where the
architecture is hierarchically partitioned into sub-clusters.  Each
sub-cluster at the same level of the architecture hierarchy has
approximately the same computing capability and has relatively local
communication. This allows us to use existing approaches that work well
for the homogeneous case to partition \textit{heterogeneous}
architectures across the sub-clusters at each level of the hierarchy. We
show that this is an effective approach if the sub-clusters are well
balanced at each level of the hierarchy.

In this section we describe our heuristic framework HMAP. There are two
important concepts that need description. First, we describe how the
topology clusters are formed from the resource graphs accounting for
communication and heterogeneity of the topology. Secondly, given a
filter graph with data parallel filters, task parallel filters, and
communication extracted as shown in Figure~\ref{fig:1b} how the mapping
is performed.

%\input{task_graph}

\input{resource_graph}

% \input{implementation}

\input{experiments}

\input{related_work}

\section{Conclusion}
\label{sec:conclusion}

In this paper we have described a novel staged graph based partitioning
technique to partition and schedule applications onto heterogeneous
execution architectures. HMAP framework considers both filter and data
parallelism, which allows the application writers to design and tune their
applications to extract parallelism. We also consider communication along
application and underlying architecture edges, which when combined with the
filter and data parallelism gives a better estimate of the application latency
than the currently described research literature targeting similar problems.

We have tested our framework on a statistical sample of randomly
generated filter graphs with varying compute, vector, communication
requirements.

%~ Moreover, we compare our technique with the well
%~ established \textit{Simulated Annealing} (SA) heuristic. Our framework
%~ outperforms SA substantially on average by XXX times. Finally, being a
%~ heuristic it can accommodate large resource graphs and filter graphs,
%~ whereas SA needs to be bounded in time (3 minutes in our case) to obtain
%~ the results.

% We have tested our framework on a subset of the many high performance
% computing applications currently in use in the industry against well
% known heterogeneous bin packing (HBP). Some of our worst case speed-ups
% were 350 times for Jacobi stencil computations and 107 times for Gram
% Schmidt linear-algebra kernel. In cases where the resource's
% capabilities did not match that of the application's requirements such
% as Gauss-Seidel stencil computations, HBP was not able to determine any
% mapping of the application. Finally, the execution time of our algorithm
% is XXX seconds even for 256 PE architectures, which makes it suitable
% for both on-line and off-line scheduling.

% Our framework was also twice as fast as HBP in the best case for Jacobi
% stencil computations. We also have speed-ups in the order of 100s for
% Binomial option pricing and Gram Schmidt which are important
% applications that are used in HPC clusters, showing that our framework
% can produce much better mapping solutions for heterogeneous
% architectures when compared to HBP.

% Our framework clearly shows that utilizing all the available
% processing elements in the underlying architecture is not a good
% solution when heterogeneity is in play. We have found that for most
% applications, given an extremely heterogeneous topology, vector strip
% size and correct placement of data plays an important role. Imbalanced
% partitioning not only gives good application latencies, but could also reduce
% power consumption.

% use section* for acknowledgment
\section{Acknowledgment}
This work is partly funded by the IRCSET Enterprise Partnership Scheme
in collaboration with IBM Research, Ireland.


% The authors would like to thank...
% more thanks here


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


\scriptsize{
\bibliographystyle{IEEEtran}
% \bibliography{latex8}
\bibliography{main_bib.bib}
}

% that's all folks
\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
